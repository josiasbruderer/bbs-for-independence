---
title: "03_Methode"
subject: ""
id: 20210719163622
lang: de-CH
author:
  - name: Josias Bruderer
    affiliation:  Universität Luzern
keywords:
  - unilu
topics:
   - 
description: ""
---

# Untersuchung von textfiles.com

Für diese Arbeit konnte ein Archiv mit BBS Text-Dateien ausfindig gemacht werden. Es wird von Jason Scott[^2] unterhalten, der nebst Archivar und Historiker Mitwirkender bei archive.org sowie Regiseur vom Film «BBS: The Documentary» ist. Der Datensatz erscheint aufgrund seines Umfanges ($N=58'0000$ Text-Dateien) und Scotts Hintergrund als geeignet, um eine Analyse von BBS Inhalten durchzuführen. Ebenfalls steht ein verkleinerter Datensatz («favorite 100») zur Verfügung, der für die Analyse hilfreich ist.

Die Analyse erfolgt in drei Schritten: Im ersten Schritt wird der verkleinerte Datensatz manuell auf inhaltliche Auffälligkeiten untersucht und daran ein Modell zur Bereinigung des gesammten Datensatzes entwickelt.[^7] Anschliessend wird im zweiten Schritt der gesammte Datensatz bereinigt. Abschliessend wird mithilfe von Techniken der NLP der bereinigte Datensatz untersucht und damit die Fragestellung zu beantworten versucht.   

## Überblick

Im verkleinerten Datensatz, «a ‹best of› collection of one hundred textfiles that [Scott] think[s] capture the spirit of this site and the unique culture that it attempts to preserve» [@jasonscottJasonScottTop], werden Auffälligkeiten zu Jahr, Länge, Struktur und Inhalt festgehalten und fliessen in den folgenden Abschnitt *Datenbereinigung* ein. Wichtig erscheint an dieser Stelle, dass es sich um durchgehend unstrukturierte Texte handelt. Auch sind die Daten trotz derer Menge «Ergebnisse historisch kontingenter Entscheidungen, wie Auswahl, Formatierung, Kombination etc. und als solche weder neutral, transparent oder objektiv, sondern immer konstruiert» [@muetzelSchoeneDatenKonstruktion2018, 112]. Dies ist für die Auswertung und das Ziehen von Schlüssen sehr relevant. Die folgenden Punkte geben einen besseren Überblick über den Datensatz:[^8]

1. Die **Variation** der Textdateien ist relativ gross und reicht von kurzen witzigen Beiträgen und Unterhaltungsverläufen, über ASCII Art bis hin zu detaillierten technischen Instruktionen und Dokumentationen sowie einer Masterarbeit und einem ganzes Buch.
2. In gewissen Textdateien wird ein **«Read X times»** ausgewiesen. Diese Zahlen sind relativ niedrig (meist <100). 
3. **Ungültige Zeichen** kommen häufig vor (z.B. «\\u1a\\u1a\\u1a»). Anhäufungen von **Sonderzeichen** dienen zur Formatierung.
4. Textdateien mit E-Mail Charakteristik können anhand **Headerparameter** wie z.B. *From, Subject, Date, Organization* erkannt werden.
5. Verschiedene **Datumsformate** sind zu finden.
6. Es kann nicht davon ausgegangen werden, dass die Textdateien **orthografisch** fehlerfrei sind. Ebenfalls ist mit ***Gunk** «(replacing U for You, 0 for O, Z for S, and similar gunk)»* zu rechnen.
7. **Inhaltlich** kommt von sauber recherchierten Artikeln und Facts bis hin zu wilder Fiktion und Ironie alles vor. 
8. Die beim Download von .zip Dateien enthaltene **index.html** repräsentiert keine BBS Textdatei.
9. Textfiles.com führt nebst den Dateien auch Titel (inkl. Jahr wenn vorhanden) und Kategorisierung sowie zum Teil eine Beschreibung auf. Diese **Metadaten** können für die Analyse nützlich sein.

## Datenbereinigung

Aus den aufgelisteten Feststellungen wird nun ein Plan entwickelt, wie die Textfiles bereinigt werden. Das Kapitel «Schöne Daten» von Sophie Mützel et al. [-@muetzelSchoeneDatenKonstruktion2018] macht deutlich, dass die Datenbereinigung oft nur marginal erwähnt wird, obschon diese elementar ist. Die Bereinigung soll für diese Arbeit daher genau durchdacht und transparent dokumentiert werden.

Bereits beim Herunterladen der Textfiles sollen unpassende Dateien (z.B. Bilder oder Audio) exkludiert werden. Gleichzeitig sollen von den verliebenen Dateien entsprechende Metadaten (9.) gespeichert werden. Dann erfolgt die erste Bereinigung, nämlich das Entfernen von Formatierungen und anderen nicht relevante Elemente (3.):

* Bereinigung von ungültigen Zeichen (\\x1a)
* Bereinigung von Zeichen die `[^A-z0-9\ \.\'\,\!]` oder `[\\\\\^\[\]]` sind
* Bereinigung von Formatierungszeichen (\\r\\n, \\r, \\n, \\t)

Anschliessend werden zusätzliche Metadaten generiert:

* Dateiname als Metadaten
* Zeichenanzahl (raw) als Metadaten
* Zeichenanzahl (bereinigt) als Metadaten
* Durchschnittliche Spaltenbreite (raw) als Metadaten
* Anteil von Fliesstext gegenüber Sonderzeichen (raw) als Metadaten
* Jahr des Textfiles (Annahme: zwischen 1960-1999) als Metadaten

Anhand dieser Metadaten kann eine erste Analyse des Datensets gemacht werden.[^10] Einerseits sollen ungeeignete Kategorien bereits zu diesem Zeitpunkt aus der Analyse ausgeschlossen werden, ebenfalls sollen geeignete Parameter für die Reduktion des Datensets gefunden werden. Die Analyse kommt zu folgendem Schluss:

* Folgende Kategorien werden ausgeschlossen, da deren Verhältnis an sinnvollen Zeichen (charratioB) unter 0.8 liegt: tap, floppies, exhibits, artifacts, piracy, art, fidonet-on-the-internet
* Folgende Kategorien werden aus der Gesammtbetrachtung ausgeschlossen, da sie eine sehr grosse Anzahl an Dateien (>10'000) beinhalten: magazines, digest
* Dateien, deren Verhältnis von Text (inkl. Satz- und Leerzeichen) zu Dateilänge unter 0.95 sind, werden ausgeschlossen.



Zusätzlich zu den ausgewerteten Textdateien wird die *Declaration* in den Textkorpus aufgenommen, damit mit dieser schliesslich verglichen werden kann. In den Metadaten (category) wird vermerkt, ob es sich um ein Textfile oder um die Declaration handelt. Die Metadaten dienen anschliessend in der Analyse des Textkorpuses dazu, eine geeignete Reduzierung der auszuwertenden Daten vorzunehmen.


## Analyse mittels NLP

Unter Natural Language Processing (NLP) werden Methoden zum maschinellen Analysieren, Modellieren und Verstehen von menschlicher Sprache verstanden [@vajjalaPracticalNaturalLanguage2020]. Allerdings ist dies nicht mit der maschinellen Erfassung von Sinn oder Bedeutung zu verwechseln, wie Emily M. Bender und Alexander Koller [-@benderClimbingNLUMeaning2020] argumentieren. Denn um ein solches Modell zu schaffen, wird eine Software mit einer grossen Menge an Daten trainiert und «if the training data is only form, there is not sufficient signal to learn the relation `M` between that form and the non-linguistic intent of human language users, nor `C` between form and the standing meaning the linguistic system assigns to each form.» [@benderClimbingNLUMeaning2020, 5187] Für gewisse Anwendungsbereiche von NLP hat dies ernstzunehmende Konsequenzen.[^9] Es ist aber gerade diese Eigenschaft, dass das Modell nur den Daten entspricht, mit welchen es gefüttert wird, die in der vorliegenden Arbeit zunutze gemacht wird. 

Aus dem bereinigten Datensatz soll ein Textkorpus generiert werden, welcher mithilfe der Python Bibliotheken «textacy» und «OCTIS» untersucht wird. #WIP: Genauer beschreiben, was für eine Analyse durchgeführt wird.









[^7]: Dieser Schritt wurde im Mini-Projekt im Rahmen des Seminars «The ABC of Computational Text Analysis» durchgeführt.
[^8]: Die Protokollierung der manuellen Untersuchung des Datensatzes ist in *Anhang 1: Top100*, der Sourcecode in *Anhang 2: Sourcecode* zu finden. Im Sourcecode entsprechen die Abschnitte R1.2 und R1.3 diesem Teilkapitel. 
[^9]: Exemplarisch am «BERT neural network» wird das beschrieben im Artikel «Machines Beat Humans on a Reading Test. But Do They Understand?», erschienen im Quanta Magazine [@pavlusMachinesBeatHumans2019].
[^10]: Dies ist in *Anhang 3: Textfiles.com Analisis* dokumentiert. 